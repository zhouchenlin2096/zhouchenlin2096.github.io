---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Hello, welcome to my website! I am currently a Ph.D. student at [Peking University](https://www.pku.edu.cn/), (since Sep. 2025), advised by Prof.[Yonghong Tian](https://ai4s.pkusz.edu.cn/info/1049/1208.htm). Before this, I worked as an algorithm engineer at [Pengcheng Laboratory](https://www.pcl.ac.cn/).  I received my Master's degree from University of Chinese Academy of Sciences / studied in [Institute of Automation, Chinese Academy of Sciences](http://www.ia.cas.cn/) in 2022, advised by Prof.[Peng Wang](https://ia.cas.cn/rcdw/qch/202404/t20240422_7129917.html).

###  Call for Collaboration !
My current research interests mainly focus on: 
- **LLM quantization, sparse, efficient reasoning**
- **Spiking Neural Networks, Spiking Transformers, Brain-inspired computing**
- **Event-data modeling and processing, Neuromorphic computing**

Open to any discussion or cooperation, feel free to contact me! 


## News
{: #News .section-title }
- [2025] I became a Ph.D. student at [Peking University](https://www.pku.edu.cn/).

- [2022] I joined [Pengcheng Laboratory](https://www.pcl.ac.cn/) as an algorithm engineer.

- [2022] Graduated from [University of Chinese Academy of Sciences](https://www.ucas.ac.cn/).



## Publications 
{: #publications .section-title }

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">AAAI 2026, Oral</span> [Spikingformer: A Key Foundation Model for Spiking Neural Networks](https://openreview.net/forum?id=SmZTeHYlCa&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DAAAI.org%2F2026%2FConference%2FAuthors%23your-submissions)),
 <ins>**Chenlin Zhou**</ins>, Liutao Yu, Zhaokun Zhou, Han Zhang, Jiaqi Wang, Huihui Zhou, Zhengyu Ma\*, Yonghong Tian\*

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">AAAI 2026</span> [
SpikCommander: A High-performance Spiking Transformer with Multi-view Learning for Efficient Speech Command Recognition](https://arxiv.org/abs/2511.07883v1),
   Jiaqi Wang, Liutao Yu, Xiongri Shen, Sihang Guo, <ins>**Chenlin Zhou**</ins>, Leilei Zhao, Yi Zhong, Zhiguo Zhang, Zhengyu Ma  <br>

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">NeurIPS 2025</span> [
S&sup2;M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection](https://arxiv.org/abs/2508.05164),
   Jiaqi Wang, Zhengyu Ma\*, Xiongri Shen, <ins>**Chenlin Zhou**</ins>, Leilei Zhao, Han Zhang, Yi Zhong, Siqi Cai, Zhenxi Song, Zhiguo Zhang\* <br>

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">Neural Networks 2025</span> [Efficient Speech Command Recognition Leveraging Spiking Neural Network and Curriculum Learning-based Knowledge Distillation](https://arxiv.org/abs/2412.12858),
   Jiaqi Wang,  Liutao Yu, Liwei Huang, <ins>**Chenlin Zhou**</ins>, Han Zhang, Zhenxi Song, Min Zhang, Zhengyu Ma, Zhiguo Zhang <br>

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">NeurIPS 2024</span> [Hierarchical Spiking Transformer using Q-K Attention](https://arxiv.org/pdf/2403.16552v2),
   <ins>**Chenlin Zhou**</ins>, Han Zhang, Zhaokun Zhou, Liutao Yu, Liwei Huang, Li Yuan,  Zhengyu Ma\*, Xiaopeng Fan, Huihui Zhou\*, and Yonghong Tian\*.  <br>

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">Frontiers in Neuroscience 2024</span>[Direct Training High-Performance Deep Spiking Neural Networks: A Review of Theories and Methods](https://arxiv.org/pdf/2405.04289),
   <ins>**Chenlin Zhou**</ins>, Han Zhang, Liutao Yu, Yumin Ye, Zhaokun Zhou, Liwei Huang, Zhengyu Ma\*, Xiaopeng Fan, Huihui Zhou, and Yonghong Tian. <br>

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">IEEE TIM 2021</span> [ACR-Net: Attention Integrated and Cross-spatial Feature Fused Rotation Network for Tubular Solder Joint Detection](https://ieeexplore.ieee.org/abstract/document/9475052/),
   <ins>**Chenlin Zhou**</ins>, Daheng Li, Peng Wang\*, Jia Sun, Yikun Huang and Wanyi Li.  <br>  IEEE Transactions on Instrumentation and Measurement(IEEE TIM).

- <span style="display:inline-block; background-color:#00369F; color:#fff; padding:0px 7px; margin-right:5px; font-size:13px;">Measurement 2021</span> [Bin-based Vector-predicted Network for Tubular Solder Joint Detection](https://www.sciencedirect.com/science/article/pii/S0263224121007697),
   <ins>**Chenlin Zhou**</ins>, Xiaofei Shen, Peng Wang\*, Wei Wei, Jia Sun, Yongkang Luo, Yiming Li.  <br>



## Academic Service
{: #academic-service .section-title }

I have experience in reviewing for high-impact AI conferences and journals, including:  

AAAI, NeurIPS, ICLR, ACM MM, IJCAI, ICME, ICRA; IEEE TIM, Neurocomputing 

## Welcome Visitors
{: #visitors .section-title }

<a href="https://clustrmaps.com/site/1c1la" title="Visit tracker">
  <img src="//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=m&d=lLNo_aaNpQ7KFqBhrFSGp8PbncZ0gy3O4oljQP1rOsk&co=2d78ad&ct=ffffff" />
</a>


## Contact
{: #Contact-me .section-title }
- E-mail: chenlinzhou25@stu.pku.edu.cn; zhouchl@pcl.ac.cn; zhouchenlin19@mails.ucas.ac.cn
- WeChat: TVSTFE


<style>
/* 整体正文字体风格：优先使用 Inter，其次系统字体 */
body, .page__content {
  font-family: "Inter", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
               "Helvetica Neue", Arial, sans-serif;
  font-size: 16px;
  line-height: 1.7;
  /* 新增：让内容区更宽并居中*/
  max-width: 1500px;
  margin-left: auto;
  margin-right: auto; 
  /* padding-left: 200px;
  padding-right: 200px;   */
}

/* 二级标题样式：左侧 emoji，右侧浅灰分隔线 */
.section-title {
  font-size: 20px;
  font-weight: 600;
  margin-top: 32px;
  margin-bottom: 10px;

  display: flex;
  align-items: center;
}

/* 右边那条分隔横线 */
.section-title::after {
  content: "";
  flex: 1;
  margin-left: 12px;
  border-bottom: 1px solid #e6e6e6;
}

/* 第一块标题不要太大的上边距 */
.page__content > .section-title:first-of-type {
  margin-top: 10px;
}

/* 列表稍微紧凑一点 */
.page__content ul {
  margin-top: 4px;
  margin-bottom: 8px;
}

/* Education 布局 */
.edu-container {
  display: flex;
  flex-direction: column;
  gap: 18px;
  margin-top: 10px;
}

.edu-item {
  display: flex;
  align-items: center;
  gap: 16px;
}

.edu-left {
  width: 140px;
  display: flex;
  gap: 10px;
  justify-content: flex-start;
}

.edu-logo {
  width: 55px;
  height: 55px;
  object-fit: contain;
}

.edu-text {
  font-size: 17px;
  line-height: 1.4;
}

/* Gallery 布局 */
.gallery {
  display: flex;
  overflow-x: auto;
  gap: 20px;
  padding: 10px 0;
}

.gallery-image {
  width: 200px;
  height: 200px;
  object-fit: cover;
  border-radius: 10px;
  flex-shrink: 0;
}
</style> 



